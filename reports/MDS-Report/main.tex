\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{tcolorbox}
\usepackage{breqn}
\usepackage{adjustbox}
\usepackage{changepage}
\usepackage{rotating}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{ntheorem}
%\usepackage[table_x &xcdraw]{xcolor}
\usepackage{longtable}
\usepackage{listings}
\usepackage{minted}

% Definition
\newtheorem{definition}{Definition}{\bfseries}{\itshape}
%\newtheorem*{definition*}{Definition}{\bfseries}{\itshape}

% Theorem
\newtheorem{theorem}{Theorem}{\bfseries}{\itshape}

% Concept
\newtheorem*{concept}{}{\bfseries}{\itshape}

\title{A history of the application of MDS matrices in cryptography}
\author{Ana Clara Zoppi Serpa\\ Prof. Dr. Ricardo Dahab \\ Dr. Jorge Nakahara Jr.}
\date{\today}

\begin{document}
%\nocite{*}

\maketitle

\tableofcontents

\chapter{A history of the application of MDS matrices in cryptography}

MDS matrices have been widely used in the construction of diffusion layers for block ciphers such as SHARK \cite{SHARK1996}, SQUARE \cite{SQUARE1997}, BKSQ \cite{BKSQ1998}, KHAZAD \cite{KHAZAD2000}, ANUBIS \cite{ANUBIS2000}, Hierocrypt-3 \cite{Hierocrypt2000}, Rijndael (AES) \cite{DesignOfRijndael2002} and Curupira \cite{barreto2007curupira}. They have also been applied in the design of hash functions (e.g Whirlwind \cite{Whirlwind2010} and Gr{\o}stl \cite{Grostl2009}). The choice is due to the fact that MDS codes provide transformations with optimal linear and differential branch numbers (see e.g \cite{SQUARE1997} or \cite{SHARK1996}), thus contributing to security against Differential and Linear Cryptanalysis attacks.

When a matrix is MDS, optimal \emph{branch number} (a measure of diffusion power) is ensured, therefore, from the theoretical security perspective, any two distinct $n \times n$ MDS matrices present equal contribution to a cipher's design in terms of diffusion power. However, their computational cost, which is a relevant practical implementation criterion, \emph{is not} necessarily the same. This motivates not only the search for MDS matrices, but the search for \emph{MDS matrices with low computational cost}. In this work, the computational cost of a matrix $A$ is measured by the amount of \textbf{xor} and \textbf{xtime} operations required when multiplying a cipher's state column vector by $A$.

Due to the computational cost of matrix multiplication, there is an interest in finding MDS matrices with coefficients as small as possible, in order to minimize the required amount of \textbf{xor} and \textbf{xtime} operations required by the implementations. However, the complexity of finding MDS matrices through random search increases proportionally to the dimension, which led to the investigation of systematic methods to construct (or find) MDS matrices. One possible avenue is trying to find direct mathematical constructions which ensure the MDS property, and another is to impose restrictions to limit the random search space (e.g imposing the matrix should be circulant, as was done by the authors of \cite{SQUARE1997}). Furthermore, there is an interest in finding involutory MDS matrices (as pointed by \cite{KHAZAD2000} and \cite{ANUBIS2000}), so that the encryption and the decryption computational cost are the same.

It is also worth noting that, although MDS matrices are widely used in cryptographic algorithms, there are designs which prefer not to make use of them. The block ciphers Serpent \cite{Serpent1998}, IDEA \cite{IDEA2000} and PRESENT \cite{PRESENT2007}, for instance, do not include MDS matrices in their design. The hash function Keccak \cite{Keccak2013}, which was later selected by NIST to become the SHA-3 standard, also does not use MDS matrices. The computational cost can be related to this choice.

In this chapter, we aim at providing a history of the application of MDS matrices in cryptography, listing the matrices, the ciphers in which they have been applied, the respective Finite Fields (order and irreducible polynomial), and their cost (amount of \textbf{xor} and \textbf{xtime} operations).

\textcolor{red}{Note: this is a partial report. It will be expanded in the future.}

We assume the reader is familiar with:
\begin{itemize}
    \item Linear branch number (see \textcolor{red}{Chapter X})
    \item Differential branch number (see \textcolor{red}{Chapter X})
    \item Differential Cryptanalysis (see \textcolor{red}{Chapter X})
    \item Linear Cryptanalysis (see \textcolor{red}{Chapter X})
    \item MDS codes (see \textcolor{red}{Chapter X} and, for further detail, reference \cite{SloaneBook})
    \item Diffusion property in cryptography (see \textcolor{red}{Chapter X})
    \item Groups, rings and fields in abstract algebra (see \textcolor{red}{Chapter X})
\end{itemize}

\section{Notation}
\begin{itemize}
    \item $det(A)$: determinant of the matrix $A$
    \item $A^{-1}$: inverse matrix of $A$
    \item $n, k, d$: parameters of a code
    \item $\mathcal{C}$: a code
    \item $G$: generator matrix of a code
    \item $I_n$: the $n \times n$ identity matrix
    \item $[I_nB]$: matrix obtained by placing the $n \times n$ matrix $B$ to the right of the $n \times n$ identity matrix $I_n$. For example, for $B = \begin{bmatrix}1 & 2 \\ 3 & 4\end{bmatrix}$, $[I_nB] = \begin{bmatrix} 1 & 0 & 1 & 2 \\ 0 & 1 & 3 & 4\end{bmatrix}$
\end{itemize}

\section{Acronyms}
\begin{itemize}
    \item MDS: Maximum Distance Separable
    %\item SHARK: refers to the SHARK cipher \cite{SHARK1996}
    %\item SQUARE: refers to the SQUARE cipher \cite{SQUARE1997}
    %\item BKSQ: refers to the BKSQ cipher \cite{BKSQ1998}
    %\item KHAZAD: refers to the KHAZAD cipher \cite{KHAZAD2000}
    %\item ANUBIS: refers to the ANUBIS cipher \cite{ANUBIS2000}
    %\item Hierocrypt-3: refers to the Hierocrypt-3 cipher \cite{Hierocrypt2000}
    %\item Rijndael: refers to the Rijndael cipher which later became AES \cite{DesignOfRijndael2002}
    \item AES: Advanced Encryption Standard (Rijndael's name after being chosen by NIST)
    %\item Curupira: refers to the Curupira cipher \cite{barreto2007curupira}
    %\item Whirlwind: refers to the Whirlwind hash function \cite{Whirlwind2010}
    %\item Gr{\o}stl: refers to the Gr{\o}stl hash function \cite{Grostl2009}
    \item \textbf{xor}: bitwise XOR between two bit strings
    \item \textbf{xtime}: refers to the multiplication by the polynomial $x$ in the finite field GF($2^m$) for an integer $m$
\end{itemize}

\section{Preliminaries}
\subsection{Linear codes}
\begin{definition}[Hamming weight \cite{SloaneBook}]
The Hamming weight $w(x)$ of a vector $x$ is the number of nonzero components of the vector $x$.
\end{definition}

\begin{definition}[Hamming distance \cite{SloaneBook}]
The Hamming distance between two vectors $x$ and $y$ is $w(x - y)$, which is equal to the Hamming weight of the difference of the two vectors.
\end{definition}

\begin{definition}[Linear code \cite{SloaneBook}]
A linear $[n, k, d]$ code over a field $\mathbb{F}$ is a $k$-dimensional subspace of the vector space $\mathbb{F}^n$, where any two different vectors of the subspace have a Hamming distance of at least $d$, and $d$ is the largest number with this property.

The distance $d$ of a linear code equals the minimum weight of a non-zero codeword in the code. A linear code can be described by generator and/or parity-check matrices.
\end{definition}

\begin{definition}[Generator matrix \cite{SloaneBook}]
A generator matrix $G$ for an $[n, k, d]$ code $C$ is a $k \times n$ matrix whose rows form a vector space basis for $C$. The choice of a basis in a vector space is not unique, thus a code has many different generator matrices which can be reduced to one another by performing elementary row operations.
\end{definition}

\begin{definition}[Parity-check matrix \cite{SloaneBook}]
A parity-check matrix $H$ for an $[n, k, d]$ code $C$ is an $(n-k) \times k$ matrix with the property that a vector $x$ is a codeword of $C$ iff $Hx^T = 0$.
\end{definition}

\begin{theorem}[Singleton Bound \cite{SloaneBook}]
If $C$ is an $[n, k, d]$ code, then $d \leq n - k + 1$.
\end{theorem}

\begin{definition}[MDS code \cite{SloaneBook}]\label{def:mds-code-singleton}
An \emph{MDS code} is a \emph{linear code} that meets the \emph{Singleton bound}, i.e a linear code with $d = n - k + 1$.
\end{definition}

An MDS matrix associated to a $[n, k, d]$ code has \emph{branch number} equal to $d$, which is the maximum possible branch number, thus providing optimal diffusion.

\subsection{Matrices}

\textcolor{red}{Obs: eu escrevi essas primeiras definições (matriz singular, involutória, circulante, circulante à esquerda, circulante à direita) com base no que eu lembrava de matemática mesmo, então por hora ainda não coloquei uma referência bibliográfica, já que são definições mais gerais e não chegam a ser específicas de cripto. Mas posso colocar depois se necessário.}

\begin{definition}[Singular matrix]
A square matrix $A$ is singular if and only if $det(A) = 0$.
\end{definition}

\begin{definition}[Non-singular matrix]
$A$ is non-singular if and only if $det(A) \neq 0$.
\end{definition}

\begin{definition}[Involutory matrix]
An $n \times n$ square matrix $A$ is involutory if $A \times A = I_n$, where $I_n$ is the identity matrix. In other words, $A$ is involutory when $A = A^{-1}$.
\end{definition}

\begin{definition}[Circulant matrix]
An $n \times n$ matrix $A$ is circulant if each row $i$ is formed by a cyclical shift of $i$ positions of the same set of elements $\{a_0, a_1, a_2, ..., a_{n-1}\}$.
\end{definition}

\begin{definition}[Left circulant matrix]
A circulant matrix in which the shift is a cyclical shift to the left, i.e

$$
A =
\begin{bmatrix}
a_0 & a_1 & ... & ... & a_{n-1}\\
a_1 & a_2 & ... & a_{n-1} & a_0\\
... & ... & ... & ... & ...\\
a_{n-1} & a_0 & ... & ... & a_{n-2}
\end{bmatrix}.
$$
\end{definition}

\begin{definition}[Right circulant matrix]
A circulant matrix in which the shift is a cyclical shift to the right, i.e

$$
A =
\begin{bmatrix}
a_0 & a_1 & ... & ... & a_{n-1}\\
a_{n-1} & a_0 & a_1 & ... & a_{n-2}\\
... & ... & ... & ... & ...\\
a_1 & ... & a_{n-2} & a_{n-1} & a_0
\end{bmatrix}.
$$
\end{definition}

Note that circulant matrices can be defined by just one row, since all the other rows are cyclical shifts of the first. Therefore, they can be denoted as $circ(a_0, a_1, ..., a_{n-1})$. In the case of left circulant and right circulant matrices, respectively, $lcirc(a_0, ..., a_{n-1})$ and $rcirc(a_0, ..., a_{n-1})$. For example, matrices (\ref{mat:rijndael}) and its inverse (\ref{mat:rijndael}), used in the Rijndael cipher, can be denoted as $rcirc(02_x, 03_x, 01_x, 01_x)$ and $rcirc(0e_x, 0b_x, 0d_x, 09_x)$.

\begin{definition}[Transpose matrix]
The transpose of a matrix $A$, denoted by $A^T$, is the matrix such that $A^T[i][j] = A[j][i]$. In other words, it is the matrix obtained by writing the rows of $A$ as columns. Note that, if $A$ is an $m \times n$ matrix, then $A^T$ will be $n \times m$.
\end{definition}

\begin{definition}[Submatrix]
Given a matrix $M$, a submatrix of $M$ is the matrix obtained after removing $z$ rows and columns of $M$, $z \geq 1$, provided that there are sufficient rows (and columns) to be removed.
\end{definition}

\begin{theorem}[MDS codes \cite{SloaneBook}]\label{teo:mds}
An $(n, k, d)$-code $\mathcal{C}$ with generator matrix $G = [I_nB]$, where $B$ is a $k \times (n - k)$ matrix, is MDS if and only if every square submatrix of $B$ is non-singular.
\end{theorem}

We call the $B$ matrix of Theorem \ref{teo:mds} the \emph{MDS matrix} throughout this work, i.e the MDS matrices we study are the $B$ matrices of the respective MDS codes chosen when designing them.
Note that Definition \ref{def:mds-code-singleton} establishes the conditions for a code to be MDS, therefore Theorem \ref{teo:mds} is an alternative way of evaluating a code, or a matrix, with respect to the MDS property.
For further detail on matrices, determinants and linear algebra, the reader may refer to \cite{LangeLinearAlgebra}.

\begin{definition}[Cauchy matrix]\label{def:cauchy}
Given $x_0, ..., x_{n-1}$ and $y_0, ..., y_{n-1}$, the matrix $A$ where $A[i][j] = \frac{1}{x_i + y_j}$ is called a Cauchy matrix. According to \cite{Youssef1997}, provided that $x_i \neq x_j$ for $0\leq i,j\leq n-1$, that $y_i \neq y_j$ for $0\leq i,j\leq n-1$ and that $x_i + y_j \neq 0$ for all $i, j$, any square submatrix of a Cauchy matrix is nonsingular over any field.
\end{definition}

An $n\times n$ matrix posesses $n^2$ elements and thus, when constructing one e.g by selecting random elements, $n^2$ choices must be made. However, Cauchy and circulant matrices allow us to lower the number of elements we need to select. A circulant matrix can be defined by one row only, therefore only $n$ elements are required. However, there are no guarantees about the MDS property. One must check whether Theorem \ref{teo:mds} holds to ensure the obtained matrix is MDS. On the other hand, a Cauchy matrix construction directly ensures the MDS property, as can be seen in Definition \ref{def:cauchy}, requiring $2n$ choices of elements (the $x_i$ and the $y_i$) to be defined. Furthermore, it is relevant to note that, albeit most matrices in this work have their dimension $n$ be a power of two such as 4 or 8, this is not a requirement for the construction. One can construct $n \times n$ circulant (or Cauchy) matrices for any arbitrary $n$.

\begin{definition}[Hadamard matrix \cite{beauchamp1975walsh}]\label{def:hadamard}
Given $n$ elements $a_0, a_1, ..., a_{n-1}$, $n$ being a power of 2, the matrix $H$ such that $H[i][j] = a_{i \oplus j}$ is a Hadamard matrix.
\end{definition}

\begin{definition}[Vandermonde matrix \cite{hoffmann1971linear}]
Given $z$ elements $a_0, a_1, ..., a_{z-1}$, the $z \times n$ matrix $V$ such that
\begin{equation}\label{eq:cost}
V =
\begin{bmatrix}
1 & a_0 & a_0^2 & ... & a_0^{n-1}\\
1 & a_1 & a_1^2 & ... & a_1^{n-1}\\
... & ... & ... & ... & ...\\
1 & a_{z-1} & a_{z-1}^2 & ... & a_{z-1}^{n-1}
\end{bmatrix}
\end{equation}
is a Vandermonde matrix.
\end{definition}

Note that Hadamard and Vandermonde constructions too allow us to lower the number of required choices to obtain a matrix. Only $n$ elements are necessary for a Hadamard matrix to be defined, provided that $n$ is a power of 2. In the case of the Vandermonde matrix, $z$ elements are required and then we must choose the number of columns $n$. Not all Vandermonde matrices are square matrices, but the notion of MDS matrix applies only to square matrices. Therefore, $z$ must be equal to $n$ if we wish to construct a Vandermonde MDS matrix. There are no guarantees about the MDS property with Hadamard or Vandermonde constructions, so we must construct the matrices and then evaluate whether they are MDS or not, e.g using Theorem \ref{teo:mds}.

In Whirlwind\cite{Whirlwind2010}, the authors make use of \emph{dyadic} matrices, defining them as a matrix $S$ such that $S[i][j] = s_{i}+{j}$ given a set $s_0, s_1, ... , s_{n-1}$ of $n$ elements. This definition matches Definition \ref{def:hadamard}, which is used in Anubis and Khazad, but referred as Hadamard instead of dyadic.

\subsection{Evaluating a matrix for MDS property}
If Theorem \ref{teo:mds} is used, the determinant of the matrix itself must be calculated, as well as the determinants of its submatrices. First, we derive a formula for the cost of calculating the determinant of an $n \times n$ matrix. Our cost unit is \emph{the number of multiplications in the finite field}, since it is the most expensive operation.

The determinant of a  $2 \times 2$ matrix $\begin{bmatrix}a & b \\ c & d\end{bmatrix}$ can be computed by means of the formula $ad - bc$, requiring therefore two multiplications.

The determinant of a $3 \times 3$ matrix can be computed by calculating cofactors of $2 \times 2$ submatrices obtained by removing a row $i$ and a column $j$. For example, the determinant of $\begin{bmatrix}a & b & c\\d & e & f\\g & h & i\end{bmatrix}$ can be computed as $a \begin{vmatrix}e & f\\h & i \end{vmatrix} + b \begin{vmatrix}d & f\\ g & i\end{vmatrix} + c \begin{vmatrix}d & e\\g & h\end{vmatrix}$, where $\begin{vmatrix}e & f\\h & i \end{vmatrix}$ denotes the determinant of the submatrix $\begin{bmatrix}e & f\\h & i \end{bmatrix}$.

The cost is therefore $3 + 3t(2)$, where $t(2)$ is the number of multiplications required to compute the determinant of a $2\times2$ matrix. We know that $t(2) = 2$, therefore the cost to obtain the determinant of a $3\times3$ matrix is $3+3\times2 = 9$, i.e $t(3) = 9$. Extending this logic, let $t(n)$ be the cost of obtaining the determinant of an $n\times n$ matrix. Then $t(n) = n + nt(n-1) = n + n(n-1 + (n-1) t(n-2)) = n + n(n-1) + n(n-1)t(n-2) = n + n(n-1) + n(n-1)(n-2) + ... + n(n-1)(n-2)..2$. For example, for $n = 4$, $t(4) = 4 + 4\times3 + 4\times3\times2 = 4 + 12 + 24 = 40$ multiplications in the finite field.

In order to evaluate a matrix for MDS property, we must compute the determinants of all its square submatrices. Let $A$ be an $n \times n$ matrix. A submatrix of $A$ is obtained by removing $z$ rows and columns of $A$. The possible values of $z$ range from $1$ to $n - 1$. When removing $n-1$ rows and columns though, only single matrix elements remain. We evaluate if they are zero or not, and this does not require multiplications in the finite field, only equality checks. When removing $z$ rows and columns, $(n - z) \times (n - z)$ submatrices are obtained, and computing a determinant costs $t(n-z)$ multiplications in the finite field. There are $2^z$ ways of choosing which rows are to be removed, and $2^z$ ways of choosing which columns are to be removed. Therefore, $2^z \times 2^z = 2^{2z}$ possible $(n - z) \times (n - z)$ submatrices, totalizing $2^{2z}$ determinants to evaluate. The cost is therefore $2^{2z}\times t(n-z)$ multiplications for a given $z$. Let $t'(z) = 2^{2z} \times t(n-z)$. Since $z$ ranges from $1$ to $n-2$, the total cost to evaluate a matrix for MDS property will be $t'(1) + t(2) + ... + t'(n-2)$.

\subsection{Abstract algebra}
\textcolor{red}{Aqui pretendo colocar definições de grupo, grupo abeliano, corpo etc. A parte de álgebra abstrata que não é específica de corpos finitos e que a gente geralmente vê na faculdade}

\subsection{Finite fields --- GF($2^m$)}

\begin{concept}[Finite field \cite{DesignOfRijndael2002}]
A \emph{finite field} is a field with a finite number of elements. The number of elements in the set is called the \emph{order} of the field.
\end{concept}

\begin{concept}[Characteristic and order \cite{DesignOfRijndael2002}]
A field with order $r$ exists if and only if $r$ is a prime power, i.e $r = p^m$ for some integer $m$, where $p$ is a prime integer. $p$ is called the \emph{characteristic} of the field. For each prime power there is exactly one finite field, denoted by GF($p^m$).
\end{concept}

\begin{concept}[Representing finite fields with prime order \cite{DesignOfRijndael2002}]
Elements of a finite field GF($p$) can be represented by the integers $0, 1, ..., p - 1$, and the field operations are integer addition modulo $p$ and integer multiplication modulo $p$.
\end{concept}

\begin{concept}[Representing finite fields with non-prime order \cite{DesignOfRijndael2002}]
For finite fields with an order $r = p^m$ that is not prime, addition and multiplication cannot be represented by addition and multiplication modulo $r$, and instead other representations must be used. One of the possible representations for GF($p^m$) is by means of \emph{polynomials over GF($p$) with degree at most $m-1$}. Addition and multiplication are then defined modulo an \emph{irreducible polynomial of degree $m$}.
\end{concept}

\begin{concept}[Polynomial \cite{DesignOfRijndael2002}]
A polynomial over a field $\mathbb{F}$ is an expression of the form

$$
b(x) = b_{m-1}x^{m-1} + b_{m-2}x^{m-2} + ... + b_2x^2 + b_1x + b_0,
$$

where $x$ is the \emph{indeterminate} and $b_i \in \mathbb{F}$ are the coefficients. The \emph{degree} of the polynomial equals $l$ if $b_j = 0$ for all $j > l$ and $l$ is the smallest number with this property.
\end{concept}

Note that, when using polynomials over GF($p$) to represent the GF($p^m$) field, the degree is at most $m-1$.

In this chapter, we focus particularly on fields with characteristic $p = 2$, due to their wide application in cryptography.

Addition and multiplication are defined on polynomials as follows.

\begin{concept}[Polynomial addition \cite{DesignOfRijndael2002}]
Summing two polynomials $a(x)$ and $b(x)$ consists of summing the coefficients with equal powers of $x$, with the sum occuring in the underlying field $\mathbb{F}$. The neutral element is 0 (the polynomial with all coefficients equal to 0). The inverse element can be found by replacing each coefficient by its inverse element in $\mathbb{F}$. The degree of $a(x) + b(x)$ is at most the maximum of the degrees of $a(x)$ and $b(x)$, therefore addition is closed.
\end{concept}

For polynomials over GF($2$) stored as integers in a cryptographic software implementation, addition can be implemented with a bitwise XOR instruction.

\begin{concept}[Polynomial multiplication \cite{DesignOfRijndael2002}]
In order to make multiplication closed, we select a polynomial $p(x)$ of degree $l$, called the \emph{reduction polynomial}. Multiplication of $a(x)$ and $b(x)$ is then defined as the algebraic product of the polynomials modulo the reduction polynomial $p(x)$.

The neutral element is 1 (the polynomial of degree 0 and with coefficient of $x^0$ equal to 1). The inverse element of $a(x)$ is $a^{-1}(x)$ such that $a(x) \times a^{-1}(x) = 1 \text{mod} p(x)$. Note that $a^{-1}(x)$ exists only when $a(x) \neq 0$.
\end{concept}

For polynomials over GF($2$) stored as integers in a cryptographic software implementation, multiplication by $x$ can be implemented as a logical bit shift followed by conditional XOR (i.e subtraction) of the reduction polynomial (the \textbf{xtime} operation). Multiplication by other polynomials can be implemented as a series of \textbf{xtime}.

The reduction polynomial is chosen as an irreducible polynomial.

\begin{concept}[Irreducible polynomial \cite{DesignOfRijndael2002}]
A polynomial $d(x)$ is irreducible over the field GF($p$) if and only if there exist no two polynomials $a(x)$ and $b(x)$ with coefficients in GF($p$) such that $d(x) = a(x) \times b(x)$, where $a(x)$ and $b(x)$ are of degree greater than 0.
\end{concept}

For further reference on abstract algebra and Finite Fields, the reader may refer to \cite{panario2007topicos}, \cite{panario2013handbook} and \cite{Handbook1996}.

\subsection{Computational cost unit}\label{sec:comp-cost}

\subsubsection{Computational cost of multiplication in GF($2^8$)}
Consider $T$ a state byte, which we multiply by the polynomial $2e_x = 00101110_2 = x^5 + x^3 + x^2 + x$ in GF($2^8$). Note that

$$
T \cdot 2e_x = T \cdot x^5 + T \cdot x^3 + T \cdot x^2 + T \cdot x = T \cdot x \cdot x \cdot x \cdot x \cdot x + T \cdot x \cdot x \cdot x + T \cdot x \cdot x + T \cdot x,
$$

where $\cdot$ denotes multiplication and $+$ denotes addition (which, in GF($2^8$), is equivalent to a bitwise XOR). Multiplication by the $x$ polynomial is performed by \textbf{xtime}, and addition is performed by \textbf{xor}.

Let $T \cdot x = Y$. Then $T \cdot 2e_x = Y + Y \cdot x + Y \cdot x \cdot x + Y \cdot x \cdot x \cdot x \cdot $.

Let $Y \cdot x = W$. Then $T \cdot 2e_x = Y + W + W \cdot x + W \cdot x \cdot x \cdot x$.

Let $W \cdot x = Z$. Then $T \cdot 2e_x = Y + W + Z + Z \cdot x \cdot x$.

The total number of \textbf{xtime} operations in this process is 5 (1 to obtain $Y$ from $T$, 1 to obtain $W$ from $Y$, 1 to obtain $Z$ from $W$, 2 to compute $Z \cdot x \cdot x$), since we can reuse intermediate \textbf{xtime} calls. The total number of \textbf{xor} operations is 3. For multiplication in GF($2^8$), in the worst case, 7 \textbf{xtime} would be necessary, since the maximum degree of polynomials in GF($2^8$) is 7.

\subsubsection{Computational cost of a matrix}
The computational cost of an $n\times n$ matrix $A$ is given by the necessary \textbf{xor} and \textbf{xtime} operations when multiplying a $n\times1$ column vector by $A$. As an example, we calculate the cost of matrix (\ref{mat:square}), used in the SQUARE \cite{SQUARE1997} cipher.

A row of matrix (\ref{mat:square}) contains the elements $01_x = 1, 02_x = x$ and $03_x = x + 1$ only. Multiplying by $01_x$ does not require \textbf{xtime} or \textbf{xor}, since $01_x \cdot T = T$. Computing $02_x \cdot T = x \cdot T$ requires 1 \textbf{xtime}. Computing $03_x \cdot T = (x + 1) \cdot T = T \cdot x + T$ requires 1 \textbf{xtime} and 1 \textbf{xor}. Furthermore, adding the row multiplication results costs 3 \textbf{xor}. Therefore, the cost of a row is 2 \textbf{xtime} and 4 \textbf{xor}. Equation \ref{eq:cost} illustrates this, with $t_1, t_2, t_3$ and $t_4$ being bytes of the state column vector.

\begin{equation}\label{eq:cost}
\begin{bmatrix}
02_x & 01_x & 01_x & 03_x\\
\end{bmatrix}
\cdot
\begin{bmatrix}
t_1\\
t_2\\
t_3\\
t_4
\end{bmatrix}
= 02_x \cdot t_1 + 01_x \cdot t_2 + 01_x \cdot t_3 + 03_x \cdot t_4
\end{equation}

Note that matrix (\ref{mat:square}) contains 4 rows, yielding a total cost of 8 \textbf{xtime} and 16 \textbf{xor}.

\section{MDS matrix catalogue}

In Table \ref{tbl:mds-list}, the \textbf{Ord} column refers to the matrix dimensions, the \textbf{Inv} column refers to whether they are involutory or not, \textbf{Use} refers to application in e.g a block cipher or hash function, \textbf{Bib} contains the bibliographic reference, \textbf{\#xor} refers to the necessary amount of \textbf{xor} operations, and \textbf{\#xtime} refers to the necessary amount of \textbf{xtime} operations. All finite fields of Table \ref{tbl:mds-list} have characteristic $p = 2$. The order is $2^m$, with $m$ being given by the degree of the irreducible polynomial in the column $GF(2)[x]/(p(x))$. For example, $m = 8$ for SHARK, SQUARE, BKSQ, KHAZAD, ANUBIS, Hierocrypt, Rijndael and the Cauchy matrix found by \cite{Youssef1997}.

\begin{footnotesize}
\begin{longtable}[c]{|l|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{Year} & \textbf{Ord} & \textbf{Type} & \textbf{Inv} & \textbf{Use} & \textbf{Bib} & \textbf{$GF(2)[x]/(p(x))$} & \textbf{\#xor} & \textbf{\#xtime} & \textbf{Matrices} \\ \hline
\endfirsthead
\endhead

% row template
% year & type & inv & use & poly & xor & xtime & mats
% SHARK
1996 & 8 & --- & no & \shortstack{SHARK} & \cite{SHARK1996} & \shortstack{$x^8 + x^7 + x^6 + x^5$\\$+ x^4 + x^2 + 1$} & \shortstack{235 \\ 223} & \shortstack{369 \\393} & \shortstack{\\ (\ref{mat:shark}) \\ (\ref{mat:shark-inv})} \\ \hline

% SQUARE
1997 & 4 & \shortstack{\\ right \\ circulant} & no & \shortstack{SQUARE} &  \cite{SQUARE1997} & \shortstack{$x^8 + x^7 + x^6 + x^5$\\$+ x^4 + x ^2 + 1$} & \shortstack{16 \\40} & \shortstack{8 \\ 48} & \shortstack{\\ (\ref{mat:square}) \\ (\ref{mat:square-inv})} \\ \hline

% Tavares
1997 & 8 & Cauchy & yes & \shortstack{---} & \cite{Youssef1997} & \shortstack{$x^8 + x^4 + x^3$\\$+ x^2 + 1$} & 240 & 344 & (\ref{mat:tavares}) \\ \hline

% BKSQ
1998 & 3 & \shortstack{\\ right \\ circulant} & no & \shortstack{BKSQ} & \cite{BKSQ1998} & \shortstack{$x^8 + x^7 + x^6 + x^5$\\$+ x^4 + x ^2 + 1$} & \shortstack{9 \\39} & \shortstack{9 \\63} & \shortstack{\\ (\ref{mat:bksq}) \\ (\ref{mat:bksq-inv})} \\ \hline

% Rijndael
1999 & 4 & \shortstack{\\ right \\ circulant} & no & \shortstack{Rijndael \\ (AES)} & \cite{DesignOfRijndael2002} & \shortstack{$x^8 + x^4 + x^3$\\$+ x + 1$} & \shortstack{16 \\40} & \shortstack{8 \\48} & \shortstack{\\ (\ref{mat:rijndael}) \\ (\ref{mat:rijndael-inv})} \\ \hline

% KHAZAD
2000 & 8 & Hadamard & yes & \shortstack{KHAZAD} & \cite{KHAZAD2000}& \shortstack{$x^8 + x^4 + x^3$\\$+ x^2 + 1$} & 112 & 120 & (\ref{mat:khazad}) \\ \hline

% ANUBIS
2000 & 4 & Hadamard & yes & \shortstack{ANUBIS} & \cite{ANUBIS2000} &\shortstack{$x^8 + x^4 + x^3$\\$+ x^2 + 1$} & 16 & 20 & (\ref{mat:anubis}) \\ \hline
2000 & 4 & Vandermonde & no & \shortstack{ANUBIS \\ key schedule} & \cite{ANUBIS2000} &\shortstack{$x^8 + x^4 + x^3$\\$+ x^2 + 1$} & 20 & 32 & (\ref{mat:anubis-ke}) \\ \hline

% Hierocrypt
2000 & 4 & \shortstack{\\ right \\ circulant} & no & \shortstack{Hierocrypt-3, \\ Hierocrypt-L1} & \shortstack{\cite{Hierocrypt2000}, \\ \cite{Hierocrypt-L1-2000}} & \shortstack{$x^8 + x^6 + x^5$\\$+x+1$} & \shortstack{52\\52} & \shortstack{108\\104} & \shortstack{(\ref{mat:hierocrypt-3-lower}) \\ (\ref{mat:hierocrypt-3-lower-inv})} \\ \hline
2000 & 4 & \shortstack{\\ right \\ circulant} & no & \shortstack{Hierocrypt-3} & \cite{Hierocrypt2000} & $x^4+x+1$ & \shortstack{32\\40} & \shortstack{40\\44} & \shortstack{(\ref{mat:hierocrypt-3-higher}) \\ (\ref{mat:hierocrypt-3-higher-inv})} \\ \hline
2000 & 4 & --- & no & \shortstack{Hierocrypt-L1} & \cite{Hierocrypt-L1-2000} & $x^4+x+1$ & \shortstack{8\\7} & \shortstack{10\\11} & \shortstack{(\ref{mat:hierocrypt-l1-higher}) \\ (\ref{mat:hierocrypt-l1-higher-inv})} \\ \hline

% FOX
2004 & 4 & --- & no & \shortstack{FOX} & \cite{FOX2004} & \shortstack{$x^8+x^7+x^6+x^5$\\$+x^4+x^3+1$} & \shortstack{30\\72} & \shortstack{25\\106} & \shortstack{(\ref{mat:fox-mu4})\\(\ref{mat:fox-mu4-inv})} \\ \hline
2004 & 8 & --- & no & \shortstack{FOX} & \cite{FOX2004} & \shortstack{$x^8+x^7+x^6+x^5$\\$+x^4+x^3+1$} & \shortstack{141\\284} & \shortstack{169\\392} & \shortstack{(\ref{mat:fox-mu8})\\(\ref{mat:fox-mu8-inv})} \\ \hline

% Curupira
2007 & 3 & --- & yes & \shortstack{Curupira} & \cite{barreto2007curupira} & \shortstack{$x^8+x^6+x^3$\\$+x^2+1$} & 12 & 15 & (\ref{mat:curupira}) \\ \hline
2007 & 3 & \shortstack{\\ right \\ circulant} & no & \shortstack{Curupira \\ key schedule} & \cite{barreto2007curupira} & \shortstack{$x^8+x^6+x^3$\\$+x^2+1$} & 27 & 36 & (\ref{mat:curupira-ke}) \\ \hline

% Grostl
2009 & 8 & \shortstack{\\ right \\ circulant} & no & \shortstack{Gr{\o}stl} & \cite{Grostl2009} & \shortstack{$x^8 + x^4 + x^3$\\$+ x + 1$} & 104 & 96 & (\ref{mat:grostl}) \\ \hline

% Whirlwind
2010 & 8 & dyadic & no & \shortstack{Whirlwind} & \cite{Whirlwind2010} & $x^4+x+1$ & 104 & 136 & (\ref{mat:whirlwind-m0}) \\ \hline
2010 & 8 & dyadic & no & \shortstack{Whirlwind} & \cite{Whirlwind2010} & $x^4+x+1$ & 128 & 128 & (\ref{mat:whirlwind-m1}) \\ \hline
\caption{MDS matrix usage and cost}\label{tbl:mds-list}
\end{longtable}
\end{footnotesize}

Matrix (\ref{mat:shark}) and its inverse (\ref{mat:shark-inv}) are used in the SHARK \cite{SHARK1996} cipher.

\begin{equation}\label{mat:shark}
\begin{bmatrix}
ce_x & 95_x & 57_x & 82_x & 8a_x & 19_x & b0_x & 01_x\\
e7_x & fe_x & 05_x & d2_x & 52_x & c1_x & 88_x & f1_x\\
b9_x & da_x & 4d_x & d1_x & 9e_x & 17_x & 83_x & 86_x\\
d0_x & 9d_x & 26_x & 2c_x & 5d_x & 9f_x & 6d_x & 75_x\\
52_x & a9_x & 07_x & 6c_x & b9_x & 8f_x & 70_x & 17_x\\
87_x & 28_x & 3a_x & 5a_x & f4_x & 33_x & 0b_x & 6c_x\\
74_x & 51_x & 15_x & cf_x & 09_x & a4_x & 62_x & 09_x\\
0b_x & 31_x & 7f_x & 86_x & be_x & 05_x & 83_x & 34_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:shark-inv}
\begin{bmatrix}
e7_x &30_x &90_x &85_x &d0_x &4b_x &91_x &41_x\\
53_x &95_x &9b_x &a5_x &96_x &bc_x &a1_x &68_x\\
02_x &45_x &f7_x &65_x &5c_x &1f_x &b6_x &52_x\\
a2_x &ca_x &22_x &94_x &44_x &63_x &2a_x &a2_x\\
fc_x &67_x &8e_x &10_x &29_x &75_x &85_x &71_x\\
24_x &45_x &a2_x &cf_x &2f_x &22_x &c1_x &0e_x\\
a1_x &f1_x &71_x &40_x &91_x &27_x &18_x &a5_x\\
56_x &f4_x &af_x &32_x &d2_x &a4_x &dc_x &71_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:square}) and its inverse (\ref{mat:square-inv}) are used in the SQUARE \cite{SQUARE1997} cipher. They are circulant.

\begin{equation}\label{mat:square}
\begin{bmatrix}
02_x & 01_x & 01_x & 03_x\\
03_x & 02_x & 01_x & 01_x\\
01_x & 03_x & 02_x & 01_x\\
01_x & 01_x & 03_x & 02_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:square-inv}
\begin{bmatrix}
0e_x & 09_x & 0d_x & 0b_x\\
0b_x & 0e_x & 09_x & 0d_x\\
0d_x & 0b_x & 0e_x & 09_x\\
09_x & 0d_x & 0b_x & 0e_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:tavares}) is involutory, and was obtained by \cite{Youssef1997} with a Cauchy construction.

\begin{equation}\label{mat:tavares}
\begin{bmatrix}
93_x & 13_x & 57_x & da_x & 58_x & 47_x & 0c_x & 1f_x\\
13_x & 93_x & da_x & 57_x & 47_x & 58_x & 1f_x & 0c_x\\
57_x & da_x & 93_x & 13_x & 0c_x & 1f_x & 58_x & 47_x\\
da_x & 57_x & 13_x & 93_x & 1f_x & 0c_x & 47_x & 58_x\\
58_x & 47_x & 0c_x & 1f_x & 93_x & 13_x & 57_x & da_x\\
47_x & 58_x & 1f_x & 0c_x & 13_x & 93_x & da_x & 57_x\\
0c_x & 1f_x & 58_x & 47_x & 57_x & da_x & 93_x & 13_x\\
1f_x & 0c_x & 47_x & 58_x & da_x & 57_x & 13_x & 93_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:khazad}) is Hadamard and involutory. It is used in the KHAZAD \cite{KHAZAD2000} cipher.

\begin{equation}\label{mat:khazad}
\begin{bmatrix}
01_x & 03_x & 04_x & 05_x & 06_x & 08_x & 0b_x & 07_x\\
03_x & 01_x & 05_x & 04_x & 08_x & 06_x & 07_x & 0b_x\\
04_x & 05_x & 01_x & 03_x & 0b_x & 07_x & 06_x & 08_x\\
05_x & 04_x & 03_x & 01_x & 07_x & 0b_x & 08_x & 06_x\\
06_x & 08_x & 0b_x & 07_x & 01_x & 03_x & 04_x & 05_x\\
08_x & 06_x & 07_x & 0b_x & 03_x & 01_x & 05_x & 04_x\\
0b_x & 07_x & 06_x & 08_x & 04_x & 05_x & 01_x & 03_x\\
07_x & 0b_x & 08_x & 06_x & 05_x & 04_x & 03_x & 01_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:anubis}) is Hadamard and involutory. It is used in the ANUBIS \cite{ANUBIS2000} cipher.

\begin{equation}\label{mat:anubis}
\begin{bmatrix}
01_x & 02_x & 04_x & 06_x\\
02_x & 01_x & 06_x & 04_x\\
04_x & 06_x & 01_x & 02_x\\
06_x & 04_x & 02_x & 01_x
\end{bmatrix}
\end{equation}

Still regarding the ANUBIS cipher, while (\ref{mat:anubis}) is used as its linear transformation layer, (\ref{mat:anubis-ke}) is used in the key extraction. It is a Vandermonde construction. When $N = 4$, it is an MDS matrix (see Theorem \ref{teo:mds}).

\begin{equation}\label{mat:anubis-ke}
\begin{bmatrix}
01_x & 01_x & 01_x & ... & 01_x\\
01_x & 02_x & 02_x^2 & ... & 02_x^{N-1}\\
01_x & 06_x & 06_x^2 & ... & 06_x^{N-1}\\
01_x & 08_x & 08_x^2 & ... & 08_x^{N-1}
\end{bmatrix}
=
\begin{bmatrix}
01_x & 01_x & 01_x & 01_x\\
01_x & 02_x & 04_x & 08_x\\
01_x & 06_x & 14_x & 78_x\\
01_x & 08_x & 40_x & 3a_x
\end{bmatrix} \text{for } N=4
\end{equation}

Matrix (\ref{mat:rijndael}) and its inverse (\ref{mat:rijndael-inv}) are used in the Rijndael \cite{DesignOfRijndael2002} cipher, which was selected to become AES. They are circulant. We show the hexadecimal notation and the corresponding polynomials to emphasize that, albeit stored as integers in cryptographic software implementation, all matrix elements are actually polynomials in a Finite Field. This applies not only to the Rijndael cipher's matrices but to all matrices listed in this work.

\begin{equation}\label{mat:rijndael}
\begin{bmatrix}
02_x & 03_x & 01_x & 01_x\\
01_x & 02_x & 03_x & 01_x\\
01_x & 01_x & 02_x & 03_x\\
03_x & 01_x & 01_x & 02_x
\end{bmatrix}
=
\begin{bmatrix}
x & x+1 & 1 & 1\\
1 & x & x+1 & 1\\
1 & 1 & x & x+1\\
x+1 & 1 & 1 & x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:rijndael-inv}
\begin{bmatrix}
0e_x & 0b_x & 0d_x & 09_x\\
09_x & 0e_x & 0b_x & 0d_x\\
0d_x & 09_x & 0e_x & 0b_x\\
0b_x & 0d_x & 09_x & 0e_x
\end{bmatrix}
=
\begin{bmatrix}
x^3+x^2+x & x^3+x+1 & x^3+x^2+1 & x^3+1\\
x^3+1 & x^3+x^2+x & x^3+x+1 & x^3+x^2+1\\
x^3+x^2+1 & x^3+1 & x^3+x^2+x & x^3+x+1\\
x^3+x+1 & x^3+x^2+1 & x^3+1 & x^3+x^2+x
\end{bmatrix}
\end{equation}

Furthermore, it is interesting to note that Rijndael's matrix (\ref{mat:rijndael}) is the transpose of SQUARE's matrix (\ref{mat:square}) and this also happens to the inverses (matrix (\ref{mat:square-inv}) is the transpose of (\ref{mat:rijndael-inv})).

Matrices (\ref{mat:bksq}) and its inverse (\ref{mat:bksq-inv}) is used in the BKSQ \cite{BKSQ1998} cipher. They are circulant.

\begin{equation}\label{mat:bksq}
\begin{bmatrix}
03_x & 02_x & 02_x\\
02_x & 03_x & 02_x\\
02_x & 02_x & 03_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:bksq-inv}
\begin{bmatrix}
ac_x & ad_x & ad_x\\
ad_x & ac_x & ad_x\\
ad_x & ad_x & ac_x
\end{bmatrix}
\end{equation}

The Hierocrypt-3 cipher makes use of two MDS matrices, one for lower level diffusion and another for higher level diffusion on the cipher, which follows a nested Substitution Permutation Network design (for more detail the reader may refer to \cite{Hierocrypt2000}). Matrix (\ref{mat:hierocrypt-3-lower}) and its inverse (\ref{mat:hierocrypt-3-lower-inv}) are used for lower level diffusion. (\ref{mat:hierocrypt-3-higher}) and (\ref{mat:hierocrypt-3-higher-inv}) (the inverse) are used for higher level diffusion. It is worth noting that, for lower level diffusion, the finite field is $GF(2^8)$, whilst, for higher level diffusion, the authors choose $GF(2^4)$.

\begin{equation}\label{mat:hierocrypt-3-lower}
\begin{bmatrix}
c4_x & 65_x & c8_x & 8b_x\\
8b_x & c4_x & 65_x & c8_x\\
c8_x & 8b_x & c4_x & 65_x\\
65_x & c8_x & 8b_x & c4_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:hierocrypt-3-lower-inv}
\begin{bmatrix}
82_x & c4_x & 34_x & f6_x\\
f6_x & 82_x & c4_x & 34_x\\
34_x & f6_x & 82_x & c4_x\\
c4_x & 34_x & f6_x & 82_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:hierocrypt-3-higher}
\begin{bmatrix}
5_x & 5_x & a_x & e_x\\
e_x & 5_x & 5_x & a_x\\
a_x & e_x & 5_x & 5_x\\
5_x & a_x & e_x & 5_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:hierocrypt-3-higher-inv}
\begin{bmatrix}
b_x & e_x & e_x & 6_x\\
6_x & b_x & e_x & e_x\\
e_x & 6_x & b_x & e_x\\
e_x & e_x & 6_x & b_x
\end{bmatrix}
\end{equation}

The Hierocrypt-L1 cipher too uses matrix (\ref{mat:hierocrypt-3-lower}) and the inverse (\ref{mat:hierocrypt-3-lower-inv}) in its lower diffusion layer. However, for the higher layer, (\ref{mat:hierocrypt-l1-higher}) and (\ref{mat:hierocrypt-l1-higher-inv}) (inverse) are used. Analogously to Hierocrypt-3, the higher layer uses $GF(2^4)$.

\begin{equation}\label{mat:hierocrypt-l1-higher}
\begin{bmatrix}
5_x & 7_x\\
a_x & b_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:hierocrypt-l1-higher-inv}
\begin{bmatrix}
c_x & a_x\\
5_x & b_x
\end{bmatrix}
\end{equation}

Matrices (\ref{mat:fox-mu4}) (inverse: (\ref{mat:fox-mu4-inv})) and (\ref{mat:fox-mu8}) (inverse: (\ref{mat:fox-mu8-inv})) are used in the FOX block cipher family, with $z = x^7+x^6+x^5+x^4+x^3+x^2+1, a = x+1, b = x^7+x, c = x, d = x^2, e = x^7+x^6+x^5+x^4+x^3+x^2$ and $f = x^6+x^5+x^4+x^3+x^2+x$.

\begin{equation}\label{mat:fox-mu4}
\begin{bmatrix}
1 & 1 & 1 & x\\
1 & z & x & 1\\
z & x & 1 & 1\\
x & 1 & z & 1
\end{bmatrix}
=
\begin{bmatrix}
01_x & 01_x & 01_x & 02_x\\
01_x & fd_x & 02_x & 01_x\\
fd_x & 02_x & 01_x & 01_x\\
02_x & 01_x & fd_x & 01_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:fox-mu8}
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & a\\
1 & a & b & c & d & e & f & 1\\
a & b & c & d & e & f & 1 & 1\\
b & c & d & e & f & 1 & a & 1\\
c & d & e & f & 1 & a & b & 1\\
d & e & f & 1 & a & b & c & 1\\
e & f & 1 & a & b & c & d & 1\\
f & 1 & a & b & c & d & e & 1
\end{bmatrix}
=
\begin{bmatrix}
01_x & 01_x & 01_x & 01_x & 01_x & 01_x & 01_x & 03_x\\
01_x & 03_x & 82_x & 02_x & 04_x & fc_x & 7e_x & 01_x\\
03_x & 82_x & 02_x & 04_x & fc_x & 7e_x & 01_x & 01_x\\
82_x & 02_x & 04_x & fc_x & 7e_x & 01_x & 03_x & 01_x\\
02_x & 04_x & fc_x & 7e_x & 01_x & 03_x & 82_x & 01_x\\
04_x & fc_x & 7e_x & 01_x & 03_x & 82_x & 02_x & 01_x\\
fc_x & 7e_x & 01_x & 03_x & 82_x & 02_x & 04_x & 01_x\\
7e_x & 01_x & 03_x & 82_x & 02_x & 04_x & fc_x & 01_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:fox-mu4-inv}
\begin{bmatrix}
7e_x & e1_x & ad_x & b0_x\\
7e_x & ad_x & b0_x & e1_x\\
7e_x & b0_x & e1_x & ad_x\\
c3_x & 7e_x & 7e_x & 7e_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:fox-mu8-inv}
\begin{bmatrix}
c6_x & fe_x & 3a_x & 73_x & 6d_x & 0c_x & d2_x & b7_x\\
c6_x & 3a_x & 73_x & 6d_x & 0c_x & d2_x & b7_x & fe_x\\
c6_x & 73_x & 6d_x & 0c_x & d2_x & b7_x & fe_x & 3a_x\\
c6_x & 6d_x & 0c_x & d2_x & b7_x & fe_x & 3a_x & 73_x\\
c6_x & 0c_x & d2_x & b7_x & fe_x & 3a_x & 73_x & 6d_x\\
c6_x & d2_x & b7_x & fe_x & 3a_x & 73_x & 6d_x & 0c_x\\
c6_x & b7_x & fe_x & 3a_x & 73_x & 6d_x & 0c_x & d2_x\\
ea_x & c6_x & c6_x & c6_x & c6_x & c6_x & c6_x & c6_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:curupira}) is used in Curupira's diffusion layer. It is involutory.

\begin{equation}\label{mat:curupira}
\begin{bmatrix}
03_x & 02_x & 02_x\\
04_x & 05_x & 04_x\\
06_x & 06_x & 07_x
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:curupira-ke}) is used in Curupira's key scheduling process, with $c(x) = x^4 + x^3 + x^2$.

\begin{equation}\label{mat:curupira-ke}
\begin{bmatrix}
1+c(x) & c(x) & c(x)\\
c(x) & 1+c(x) & c(x)\\
c(x) & c(x) & 1+c(x)
\end{bmatrix}
\end{equation}

Matrix (\ref{mat:grostl}) is used in the Gr{\o}stl hash function. It is circulant.

\begin{equation}\label{mat:grostl}
\begin{bmatrix}
02_x & 02_x & 03_x & 04_x & 05_x & 03_x & 05_x & 07_x\\
07_x & 02_x & 02_x & 03_x & 04_x & 05_x & 03_x & 05_x\\
05_x & 07_x & 02_x & 02_x & 03_x & 04_x & 05_x & 03_x\\
03_x & 05_x & 07_x & 02_x & 02_x & 03_x & 04_x & 05_x\\
05_x & 03_x & 05_x & 07_x & 02_x & 02_x & 03_x & 04_x\\
04_x & 05_x & 03_x & 05_x & 07_x & 02_x & 02_x & 03_x\\
03_x & 04_x & 05_x & 03_x & 05_x & 07_x & 02_x & 02_x\\
02_x & 03_x & 04_x & 05_x & 03_x & 05_x & 07_x & 02_x
\end{bmatrix}
\end{equation}

Matrices (\ref{mat:whirlwind-m0}) and (\ref{mat:whirlwind-m1}) are used in the Whirlwind hash function.

\begin{equation}\label{mat:whirlwind-m0}
\begin{bmatrix}
5_x & 4_x & a_x & 6_x & 2_x & d_x & 8_x & 3_x\\
4_x & 5_x & 6_x & a_x & d_x & 2_x & 3_x & 8_x\\
a_x & 6_x & 5_x & 4_x & 8_x & 3_x & 2_x & d_x\\
6_x & a_x & 4_x & 5_x & 3_x & 8_x & d_x & 2_x\\
2_x & d_x & 8_x & 3_x & 5_x & 4_x & a_x & 6_x\\
d_x & 2_x & 3_x & 8_x & 4_x & 5_x & 6_x & a_x\\
8_x & 3_x & 2_x & d_x & a_x & 6_x & 5_x & 4_x\\
3_x & 8_x & d_x & 2_x & 6_x & a_x & 4_x & 5_x
\end{bmatrix}
\end{equation}

\begin{equation}\label{mat:whirlwind-m1}
\begin{bmatrix}
5_x & e_x & 4_x & 7_x & 1_x & 3_x & f_x & 8_x\\
e_x & 5_x & 7_x & 4_x & 3_x & 1_x & 8_x & f_x\\
4_x & 7_x & 5_x & e_x & f_x & 8_x & 1_x & 3_x\\
7_x & 4_x & e_x & 5_x & 8_x & f_x & 3_x & 1_x\\
1_x & 3_x & f_x & 8_x & 5_x & e_x & 4_x & 7_x\\
3_x & 1_x & 8_x & f_x & e_x & 5_x & 7_x & 4_x\\
f_x & 8_x & 1_x & 3_x & 4_x & 7_x & 5_x & e_x\\
8_x & f_x & 3_x & 1_x & 7_x & 4_x & e_x & 5_x
\end{bmatrix}
\end{equation}

\section{A note on Hierocrypt 3 and Hierocrypt-L1}
In the Hierocrypt 3 and Hierocrypt-L1 ciphers, there are two different diffusion layers, referred as low level ($mds_l$) and high level ($MDS_H$) by the authors, since these ciphers follow a nested SPN structure (for more details please refer to \cite{Hierocrypt2000} and \cite{Hierocrypt-L1-2000}). Their high level diffusion layer is called $MDS_H$ and is based on multiplication by matrices (\ref{mat:hierocrypt-3-higher}) (for Hierocrypt 3) and (\ref{mat:hierocrypt-l1-higher}) (for Hierocrypt-L1). They are both MDS, as stated in the design rationale section of the ciphers' specification documents (see \cite{Hierocrypt2000} and \cite{Hierocrypt-L1-2000}). However, for the implementation, the $MDS_H$ transformation can be equivalently expressed as multiplication by a $16 \times 16$ binary matrix which is \emph{not MDS}, but yields the same result. In \cite{Hierocrypt2000}, they state \begin{quote}``$MDS(32, 4)$ consists of eight parallel $MDS(4,4)$. When all $MDS(4,4)$ are the same, $MDS_H$ is nothing but the combination of byte-wise XOR's and is expressed as $16 \times 16$ matrix."\end{quote}

See for example matrix \ref{mat:hierocrypt-3-higher-16x16}, which is the binary matrix used for $MDS_H$ in Hierocrypt 3. We can see that it is not MDS, since it has a zero element (see Theorem \ref{teo:mds}).

\begin{equation}\label{mat:hierocrypt-3-higher-16x16}
\begin{bmatrix}
1010101011011111\\
1101110111100111\\
1110111011110011\\
0101010110101110\\
1111101010101101\\
0111110111011110\\
0011111011101111\\
1110010101011010\\
1101111110101010\\
1110011111011101\\
1111001111101110\\
1010111001010101\\
1101111001111101\\
1110111100111110\\
0101101011100101
\end{bmatrix}
\end{equation}

\section{About the irreducible polynomials}
\textcolor{red}{yet to be written}

\section{Computing \textbf{xtime} and \textbf{xor} of the matrices}

One can compute the costs manually, however, the following following C code can also be used for this purpose, considering that polynomials in GF($2^8$) are stored in integers (a set bit means coefficient equal to 1, a zero bit means coefficient equal to 0).

For e.g SHARK and SQUARE, the field order is equal to 8, therefore \texttt{ORDER} must be set to 8 and \texttt{DEGREE_LIMIT_MASK} must be set to $x^8$.

\begin{minted}{C}
#define DEGREE_LIMIT_MASK 0x100
#define ORDER 8
\end{minted}

The following function obtains the amount of \textbf{xtime} required to multiply by the polynomial.

\begin{minted}{C}
unsigned int poly_xtime_cost(unsigned int poly) {
	unsigned int degree_mask = DEGREE_LIMIT_MASK;
	unsigned int degree = ORDER;
	while ((poly & degree_mask) == 0) {
		degree_mask >>= 1;
		degree--;
	}
	return degree;
}
\end{minted}

The following function obtains the amount of \textbf{xor} required to multiply by the polynomial.
\begin{minted}{C}
unsigned int poly_xor_cost(unsigned int poly) {
	unsigned int mask = 1;
	unsigned int set_bits = 0;
	unsigned int current_bit = 0;
	while (current_bit <= ORDER) {
		set_bits += ((poly & mask) != 0);
		mask <<= 1;
		current_bit++;
	}
	return set_bits - 1;
}
\end{minted}

And, to compute the \textbf{xtime} and \textbf{xor} costs of a matrix, we must sum the costs of each row, which is accomplished by the following functions. Note that for e.g SHARK \texttt{DIM} must be set to 8, for SQUARE, to 4, and so forth.

\begin{minted}{C}
#define DIM 8

unsigned int matrix_xtime_cost(unsigned int mat [DIM][DIM]) {
	unsigned int total_cost = 0;
	for (int row = 0; row < DIM; row++) {
		unsigned int row_cost = 0;
		for (int col = 0; col < DIM; col++) {
			row_cost += poly_xtime_cost(mat[row][col]);
		}
		printf("Row %d costs %d xtime\n", row, row_cost);
		total_cost += row_cost;
	}
	printf("The full matrix costs %d xtime\n", total_cost);
	return total_cost;
}

unsigned int matrix_xor_cost(unsigned int mat[DIM][DIM]) {
	unsigned int total_cost = 0;
	for (int row = 0; row < DIM; row++) {
		unsigned int row_cost = DIM - 1; //sum elements
		for (int col = 0; col < DIM; col++) {
			row_cost += poly_xor_cost(mat[row][col]);
		}
		printf("Row %d costs %d xor\n", row, row_cost);
		total_cost += row_cost;
	}
	printf("The full matrix costs %d xor\n", total_cost);
	return total_cost;
}
\end{minted}

\subsection{SQUARE manual calculation example}
The computational cost for matrix (\ref{mat:shark}), used in the SQUARE cipher, was explained in Section \ref{sec:comp-cost}.

For matrix (\ref{mat:square-inv}), used in SQUARE's decryption process, each row contains elements from $\{0e_x, 09_x, 0d_x, 0b_x\}$.

\begin{equation*}
0e_x = 00001110_2 = x^3 + x^2 + x \text{ requires 3 \textbf{xtime} and 2 \textbf{xor} }
\end{equation*}

\begin{equation*}
09_x = 00001001_2 = x^3 + 1 \text{ requires 3 \textbf{xtime} and 1 \textbf{xor} }
\end{equation*}

\begin{equation*}
0d_x = 00001101_2 = x^3 + x^2 + 1 \text{ requires 3 \textbf{xtime} and 2 \textbf{xor} }
\end{equation*}

\begin{equation*}
0b_x = 00001011_2 = x^3 + x + 1 \text{ requires 3 \textbf{xtime} and 2 \textbf{xor} }
\end{equation*}

There are 3 \textbf{xor} to add the intermediate row multiplication results, totalizing 12 \textbf{xtime} and 10 \textbf{xor} per row. There are 4 rows, hence 48 \textbf{xtime} and 40 \textbf{xor}.

\section{Conclusions}
\textcolor{red}{yet to be written}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
